# DS_DBLP
DBLP分布式查询系统
项目环境

项目搭建在三台腾讯云服务器中，通过Idea编译器的远程连接进行Java开发及测试：

操作系统：Centos 7.6 及 Ubuntu 20.04

JavaSdk：1.8

服务器之间通过公网IP进行通信。

每个服务器上通过运行不同的线程，使用不同的端口来创建出多个虚拟机，在本项目中我们让每个服务器都运行2-3个虚拟机。

### 存储负载均衡

本项目中共设置了6个虚拟机作为服务器，为了实现存储负载均衡，我们将原本的dblp.xml切分为了总计24个片段XML，然后每个虚拟机负责存储4个片段，对于24个片段各个片段之间的平衡，我们采用的方法如下：在某台虚拟机上执行拆分程序，该程序将创建24个文件写流，在此由于我们要写的是XML文件，为了保持格式，我们使用XMLStreamWriter作为文件的写流；创建完24个文件流之后，我们借助java中的StAX库（不需要整个XML加载进内存，而是不断的读取），对原本的dblp.xml进行解析，每当遇到一个类似于<article>,<book>,<proceedings>...的信息块，我们都在24个文件流中随机选取一个作为输出，把读取到的这一个完整的信息块输出到被选到的文件流中，直到dblp.xml读取完毕，在多次的随机选取下，最终切分后的24个片段XML文件的大小保持均衡，基本都为128MB左右。

### 通信模式

本项目中的通信存在两种情况：

一是某个虚拟机执行切分dblp.xml文件的程序后，需要将其分发给各个（共计6个）实际负责存储的虚拟机，这种情况下该执行切分任务的虚拟机切分完成后，作为客户端执行分发程序将分好的xml片段文件分发给各个负责存储的虚拟机，每个负责存储的虚拟机需要作为服务端监听发送文件的请求，并接收并存储XML片段文件。

二是查询时需要进行的通信，即1个查询客户端和6个服务端之间的通信，查询客户端向6个服务端分别发送查询请求，并传给服务端要查的 author 和 year 信息；服务端则在进行自己的本地查询，得到了结果之后，告诉客户端自己这个服务器上的对应论文频次。客户端收到了6个服务端的返回信息后，进行汇总，得到结果。在此过程之中，为了借助分布式系统的特点提升性能，我们在客户端向6个服务端发送查询请求的时候，分别开启6个线程去和对应的服务端通信，使得6个服务端并行开启查询，最终6个线程都结束后，即完成了查询。

### 查询机制

查询工作的实际开展由每个虚拟机进行， 每个虚拟机负责查询自己负责存储的所有XML片段文件，对所有XML片段文件中的频次进行统计过后计算出属于该虚拟机的论文频次的总和，返回给发起查询请求的客户端。

具体来说，每个虚拟机上的查询工作分为两种，一是只根据Author进行查询，二是根据Author和Year进行查询：前者实现方式有两种，一种是直接使用grep+wc的方式搜索每个XML片段文件中的Author字段共出现了多少次（行），以此作为查询的结果，另一种是解析XML，对XML文件中的每个类似于<article>,<book>,<proceedings>...的块，扫描其中是否存在某个<author>块中的信息满足要求；后者的实现方式也是解析XML，对XML文件中的每个类似于<article>,<book>,<proceedings>...的块，扫描其中的<year>块中的信息是否满足年份区间的要求，并且是否存在某个<author>块中的信息满足要求，满足则计数++。（解析XML所用的java库为StAX）

### 查询容错

在查询发起客户端虚拟机不会出现故障、而 N 个存储虚拟机存在故障的可能性的条件下，本项目采用的查询容错机制可以允许至多N/2个存储虚拟机出现故障的情况下还可以正确的查询结果。具体如下：

首先我们在每个存储虚拟机（服务端）上，都设置了两个目录，一个用以存放正常的XML片段文件，另一个专门用以存储备份类型的文件。而在分发过程中，对于总计24个XML片段文件，每个都发送两遍，一遍作为正常文件发送给某个服务器，另一边作为备份文件按照固定规则发送给另外一个服务器，最终形成的结果便类似下图所示：

![](https://cy89r0pvke.feishu.cn/space/api/box/stream/download/asynccode/?code=Y2M5NTk4ZDE4MjIxZjYzNDhhMjA0MzE3YmNiZjNjOGNfYTR0dDdBTG91WDU2Zk9qdU1YUk9pMXFrbEhRQ3Q2eHRfVG9rZW46Ym94Y243SEt6QTFGZlZZUVBBV0VTWWhoNExkXzE2NzE0MzY0NDY6MTY3MTQ0MDA0Nl9WNA)

因此至多可以允许N/2个存储虚拟机发生故障无法提供查询服务。若在查询时遇到某个虚拟机无法正确返回结果，便前往其对应的备份内容所在虚拟机进行查询。

### 加分项：本地索引机制

为了加快服务端的搜索速度，考虑添加本地索引结构，本项目中的本地索引机制的实现如下：

首先本项目中我们使用的是哈希表的思想，计划使用哈希表结构来存储索引信息，哈希表是一种数据结构，可以通过将数据存储在键值对中，并通过哈希函数将键映射到特定的索引位置，来实现快速查找和插入操作。在本题的查询中，因为只涉及到 Author 和 Year ，因此以 author 和 year 作为键值，并使用哈希函数将它们映射到哈希表中的特定索引位置，同时统计论文频次。

具体来说，我们首先在内存创建一个哈希表，此处设置的哈希表的结构为数组+集合（java中的set)的形式，整个哈希表就是一个集合数组，数组大小为101，即共计有101个集合，将 author 和 year 和论文频次作为键值对，存储在哈希表中，索引位置则是根据Author和Year信息计算出来的哈希值。

然后针对每一个XML片段文件去逐次进行处理，解析出每个信息块中 author 和 year 的相关信息并使用哈希函数对 author 和 year 进行哈希计算，得到它们的哈希值，据此哈希值确定这一条信息应该存储在哪个集合之中，然后将其添加到集合。p.s.此处为了减少整个哈希表的大小（主要是为了减小其在内存中的占用），我们将某条信息加到集合时不是直接加入，而是查找有没有相同的信息，有则在频次信息上++，当然，这增加了构建索引时的时间复杂度，但与此同时我们既减少了内存的压力也在一定程度上加快了查询时的速度，权衡考虑之下决定采用这种方式。

在对某个XML片段文件的内容构建好哈希表后，开始将其写入磁盘，我们针对每个XML片段文件新建一个目录，其中存储其对应的哈希表中的所有集合（即101个set），每个set使用java中提供的序列化手段进行写入，将一整个set这个Object作为整体序列化写入到.ser文件中，最终得到101个.ser文件。

到了查询阶段，则对虚拟机负责存储的每个XML片段文件进行索引方式的查询，即对每个XML片段文件建立出的索引目录，分别进行查询，首先需要根据输入的 author 和 year 的信息进行计算得到其对应的哈希值，在此由于year信息是一个区间，而author是一个值，因此我们认为实际上只根据author的信息进行哈希计算能够更好契合需求，提高性能，因此我们的哈希函数实际上只对传入的author参数进行计算，具体的计算方式为：

```java
for (int i = 0; i < bytes.length; i++) {
    result += bytes[i];
}
```

得到了哈希值后，我们就知道选择哪一个.ser文件加载回内存了，将.ser文件反序列化后，我们将获得一个set，然后在此set中查找满足要求的信息条目并加以统计即可完成查询工作。
